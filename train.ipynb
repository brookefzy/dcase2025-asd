{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b10d5913",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scr/u/yuanzf/anaconda3/envs/octa312/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, ConcatDataset, Dataset\n",
    "import os\n",
    "from datasets.dataset_spec import SpectrogramDataset\n",
    "from torch.nn.functional import adaptive_avg_pool2d\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, precision_score,\n",
    "    recall_score, f1_score\n",
    ")\n",
    "\n",
    "from datasets.loader_common import (\n",
    "    select_dirs,\n",
    "    get_machine_type_dict,\n",
    ")\n",
    "from models.branch_pretrained    import BranchPretrained\n",
    "from models.branch_transformer_ae import BranchTransformerAE\n",
    "from models.branch_contrastive   import BranchContrastive\n",
    "from models.branch_diffusion     import BranchDiffusion\n",
    "from models.branch_flow          import BranchFlow\n",
    "from models.fusion_attention     import FusionAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0584b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result columns you requested\n",
    "result_column_dict = {\n",
    "    \"single_domain\": [\n",
    "        \"section\", \"AUC\", \"pAUC\", \"precision\", \"recall\", \"F1 score\"\n",
    "    ],\n",
    "    \"source_target\": [\n",
    "        \"section\",\n",
    "        \"AUC (source)\", \"AUC (target)\",\n",
    "        \"pAUC\",\n",
    "        \"pAUC (source)\", \"pAUC (target)\",\n",
    "        \"precision (source)\", \"precision (target)\",\n",
    "        \"recall (source)\", \"recall (target)\",\n",
    "        \"F1 score (source)\", \"F1 score (target)\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a9dfe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, path):\n",
    "    torch.save({\n",
    "        'epoch':       epoch,\n",
    "        'model_state': model.state_dict(),\n",
    "        'optim_state': optimizer.state_dict()\n",
    "    }, path)\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    secs, scores, labels = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for feats, labs, sections in loader:\n",
    "            # feats: [B, H, W]  →  x: [B,1,H,W]\n",
    "            x     = feats.to(device).squeeze().unsqueeze(1)\n",
    "            labs  = labs.to(device)\n",
    "\n",
    "            # ── Branch 1: embedding only ────────────────────────────\n",
    "            z1 = b1(x)\n",
    "\n",
    "            # ── Branch 2: transformer‐AE + reconstruction loss ──────\n",
    "            recon2, z2 = b2(x)\n",
    "            loss2 = F.mse_loss(recon2, x)\n",
    "\n",
    "            # ── Branch 3: contrastive, returns (z3, loss3) ─────────\n",
    "            z3, loss3 = b3(x, labs)\n",
    "\n",
    "            # ── Branch 5: fusion input branch ───────────────────────\n",
    "            z_cat = torch.cat([z1, z2, z3], dim=1)\n",
    "            loss5 = b5(z_cat)\n",
    "\n",
    "            # ── Fusion: stack the three anomaly scores and predict ──\n",
    "            # shape: [B, 3]\n",
    "            anomaly_vector = torch.stack([loss2, loss3, loss5], dim=1)\n",
    "            scores_batch   = fusion(anomaly_vector)\n",
    "\n",
    "            # ── Collect for metrics ─────────────────────────────────\n",
    "            scores.extend(scores_batch.cpu().tolist())\n",
    "            labels.extend(labs.cpu().tolist())\n",
    "            secs.extend(sections)\n",
    "\n",
    "    # ── Per‐section aggregation ─────────────────────────────────\n",
    "    df      = pd.DataFrame({'section': secs, 'score': scores, 'label': labels})\n",
    "    results = []\n",
    "    for sec, grp in df.groupby('section'):\n",
    "        y_true   = grp['label'].values\n",
    "        y_score  = grp['score'].values\n",
    "\n",
    "        auc_val   = roc_auc_score(y_true, y_score)\n",
    "        p_auc_val = roc_auc_score(y_true, y_score, max_fpr=0.1)\n",
    "        preds     = (y_score >= 0.5).astype(int)\n",
    "\n",
    "        results.append({\n",
    "            'section':   sec,\n",
    "            'AUC':       auc_val,\n",
    "            'pAUC':      p_auc_val,\n",
    "            'precision': precision_score(y_true, preds, zero_division=0),\n",
    "            'recall':    recall_score(y_true, preds, zero_division=0),\n",
    "            'F1 score':  f1_score(y_true, preds, zero_division=0)\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "# wrap to attach labels & section\n",
    "class WrappedSpecDS(Dataset):\n",
    "    def __init__(self, ds, train: bool):\n",
    "        self.ds    = ds\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # grab whatever the underlying dataset returns\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        # unpack first two elements, ignore any extras\n",
    "        spec, fname, *rest = item   # rest could be an attr‐dict, metadata, etc.\n",
    "\n",
    "        # label = 0 for normal in train, or infer anomaly from filename\n",
    "        lbl = 0 if self.train else int(\"_anomaly_\" in fname)\n",
    "\n",
    "        # extract section code (e.g. \"00\")\n",
    "        sec = fname.split(\"_\")[1]\n",
    "\n",
    "        return spec, lbl, sec\n",
    "\n",
    "\n",
    "def pad_collate(batch):\n",
    "    specs, labels, secs = zip(*batch)  \n",
    "    # each spec is [1, H, Wi]\n",
    "    max_W = max(s.shape[-1] for s in specs)\n",
    "    padded = [\n",
    "        F.pad(s, (0, max_W - s.shape[-1]))   # keeps shape [1, H, max_W]\n",
    "        for s in specs\n",
    "    ]\n",
    "    specs_tensor = torch.stack(padded, dim=0)  # [B,1,H,max_W]\n",
    "    labels_tensor = torch.tensor(labels)\n",
    "    return specs_tensor, labels_tensor, list(secs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad990c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 23:25:18,701 - INFO - load_directory <- development\n"
     ]
    }
   ],
   "source": [
    "# ── Settings ───────────────────────────────────────────────────────────\n",
    "mode            = 'dev'\n",
    "config_path     = \"/lustre1/g/geog_pyloo/11_octa/dcase2025-asd/config.yaml\"\n",
    "baseline_config = \"/lustre1/g/geog_pyloo/11_octa/dcase2023_task2_baseline_ae/baseline.yaml\"\n",
    "device          = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cfg     = yaml.safe_load(open(config_path))\n",
    "root    = cfg['dev_data_root'] if mode=='dev' else cfg['eval_data_root']\n",
    "name    = 'DCASE2025T2'\n",
    "param   = yaml.safe_load(open(baseline_config))\n",
    "param[\"dev_directory\"] = \"/lustre1/g/geog_pyloo/11_octa/dcase2023_task2_baseline_ae/data/dcase2025t2/dev_data/raw\"\n",
    "base_dirs = select_dirs(param, mode=(mode=='dev'))\n",
    "\n",
    "mt_dict   = get_machine_type_dict(name, mode=(mode=='dev'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd71d7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AST pos-emb old_len=1214, new_len=252\n",
      "AE pos-emb len: 252\n",
      "Expected seq_len: 252\n"
     ]
    }
   ],
   "source": [
    "train_dsets = []\n",
    "eval_dsets  = []\n",
    "\n",
    "for mt, sect_info in mt_dict['machine_type'].items():\n",
    "    for sec in sect_info['dev']:\n",
    "        # raw spectrogram datasets:\n",
    "        ds_train_raw = SpectrogramDataset(\n",
    "            base_dir     = cfg['dev_data_root'],\n",
    "            machine_type = mt,\n",
    "            section      = sec,\n",
    "            mode         = 'train',\n",
    "            config       = cfg\n",
    "        )\n",
    "        ds_sup_raw   = SpectrogramDataset(\n",
    "            base_dir     = cfg['dev_data_root'],\n",
    "            machine_type = mt,\n",
    "            section      = sec,\n",
    "            mode         = 'supplemental',\n",
    "            config       = cfg\n",
    "        )\n",
    "        ds_test_raw  = SpectrogramDataset(\n",
    "            base_dir     = cfg['dev_data_root'],\n",
    "            machine_type = mt,\n",
    "            section      = sec,\n",
    "            mode         = 'test',\n",
    "            config       = cfg\n",
    "        )\n",
    "\n",
    "        # wrap them so that each sample = (spec, label:int, section:str)\n",
    "        if len(ds_train_raw):\n",
    "            train_dsets.append(WrappedSpecDS(ds_train_raw, train=True))\n",
    "        if len(ds_sup_raw):\n",
    "            train_dsets.append(WrappedSpecDS(ds_sup_raw,   train=True))\n",
    "        if len(ds_test_raw):\n",
    "            eval_dsets.append(WrappedSpecDS(ds_test_raw,  train=False))\n",
    "\n",
    "\n",
    "# concatenate all per-section datasets\n",
    "full_train_ds = ConcatDataset(train_dsets)\n",
    "full_eval_ds  = ConcatDataset(eval_dsets)\n",
    "\n",
    "# finally, wrap in DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    full_train_ds,\n",
    "    batch_size=cfg['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=pad_collate\n",
    ")\n",
    "\n",
    "eval_loader = DataLoader(\n",
    "    full_eval_ds,\n",
    "    batch_size   = cfg['batch_size'],\n",
    "    shuffle      = False,\n",
    "    # num_workers  = cfg.get('num_workers', 4)\n",
    "    num_workers = 0,\n",
    "    collate_fn=pad_collate\n",
    ")\n",
    "\n",
    "\n",
    "# ── Instantiate branches ────────────────────────────────────────────────\n",
    "b1 = BranchPretrained(cfg['ast_model'], cfg).to(device)\n",
    "b2 = BranchTransformerAE(cfg['latent_dim'], cfg).to(device)\n",
    "\n",
    "print(\"AE pos-emb len:\", b2.encoder.embeddings.position_embeddings.shape[1])\n",
    "print(\"Expected seq_len:\", 2 + ((cfg['n_mels'] - b2.encoder.config.patch_size)//b2.encoder.config.frequency_stride + 1) *\n",
    "                                ((cfg['time_steps'] - b2.encoder.config.patch_size)//b2.encoder.config.time_stride + 1))\n",
    "\n",
    "b3 = BranchContrastive(cfg['latent_dim'], cfg).to(device)\n",
    "# b4 = BranchDiffusion(\n",
    "#     image_size     = (cfg['n_mels'], cfg['time_steps']),                # height of spectrogram\n",
    "#     unet_dim       = cfg['diffusion_unet_dim'],    # UNet base channels\n",
    "#     unet_dim_mults = tuple(cfg['diffusion_mults']),# UNet channel multipliers\n",
    "#     timesteps      = cfg['diffusion_steps']        # diffusion steps\n",
    "# ).to(device)\n",
    "b5     = BranchFlow(cfg['flow_dim']).to(device)\n",
    "fusion = FusionAttention(num_branches=4).to(device)\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    list(b1.parameters()) + \n",
    "    list(b2.parameters()) +\n",
    "    list(b3.parameters()) + \n",
    "    # list(b4.parameters()) +\n",
    "    list(b5.parameters()) + \n",
    "    list(fusion.parameters()),\n",
    "    lr=float(cfg['lr'])\n",
    ")\n",
    "\n",
    "best_auc = 0.0\n",
    "os.makedirs(cfg['save_dir'], exist_ok=True)\n",
    "\n",
    "metrics_csv = os.path.join(cfg['save_dir'], 'metrics_all_epochs.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "472636d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b1.train(); b2.train(); b3.train(); b4.train(); b5.train(); fusion.train()\n",
    "# with torch.no_grad():\n",
    "#     dummy = torch.randn(2,1, cfg['n_mels'], cfg['time_steps']).to(device)\n",
    "#     z1 = b1(dummy)  # should now succeed without errors\n",
    "# print(\"BranchPretrained forward OK →\", z1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57fd5440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "099fa7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 64, 512])\n",
      "z1.shape = torch.Size([16, 128])\n",
      "enc_out: torch.Size([16, 252, 512]) dec_inp: torch.Size([16, 1, 512])\n",
      "recon2.shape = torch.Size([16, 1, 64, 252]), feats.shape = torch.Size([16, 1, 64, 512])\n",
      "z2.shape = torch.Size([16, 128])\n",
      "z3.shape = torch.Size([16, 128]), feats_ds.shape = torch.Size([16, 1, 64, 252])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# loss4    = b4(feats)\u001b[39;00m\n\u001b[32m     23\u001b[39m z_cat    = torch.cat([z1, z2, z3], dim=\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m loss5    = \u001b[43mb5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_cat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m total_branch_loss = (\n\u001b[32m     27\u001b[39m     cfg[\u001b[33m'\u001b[39m\u001b[33mw2\u001b[39m\u001b[33m'\u001b[39m]*loss2 + \n\u001b[32m     28\u001b[39m     cfg[\u001b[33m'\u001b[39m\u001b[33mw3\u001b[39m\u001b[33m'\u001b[39m]*loss3 +\n\u001b[32m     29\u001b[39m     \u001b[38;5;66;03m# cfg['w4']*loss4 + \u001b[39;00m\n\u001b[32m     30\u001b[39m     cfg[\u001b[33m'\u001b[39m\u001b[33mw5\u001b[39m\u001b[33m'\u001b[39m]*loss5\n\u001b[32m     31\u001b[39m )\n\u001b[32m     32\u001b[39m optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scr/u/yuanzf/anaconda3/envs/octa312/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scr/u/yuanzf/anaconda3/envs/octa312/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/lustre1/g/geog_pyloo/11_octa/dcase2025-asd/models/branch_flow.py:13\u001b[39m, in \u001b[36mBranchFlow.forward\u001b[39m\u001b[34m(self, z)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, z):\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     logp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m -logp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scr/u/yuanzf/anaconda3/envs/octa312/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scr/u/yuanzf/anaconda3/envs/octa312/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/lustre1/g/geog_pyloo/11_octa/dcase2025-asd/models/flow.py:52\u001b[39m, in \u001b[36mNormalizingFlow.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     50\u001b[39m     log_det_sum += log_det\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# x is now in base space\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m log_prob = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprior\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m + log_det_sum\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m log_prob\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scr/u/yuanzf/anaconda3/envs/octa312/lib/python3.12/site-packages/torch/distributions/multivariate_normal.py:250\u001b[39m, in \u001b[36mMultivariateNormal.log_prob\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._validate_args:\n\u001b[32m    249\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_sample(value)\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m diff = \u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\n\u001b[32m    251\u001b[39m M = _batch_mahalanobis(\u001b[38;5;28mself\u001b[39m._unbroadcasted_scale_tril, diff)\n\u001b[32m    252\u001b[39m half_log_det = (\n\u001b[32m    253\u001b[39m     \u001b[38;5;28mself\u001b[39m._unbroadcasted_scale_tril.diagonal(dim1=-\u001b[32m2\u001b[39m, dim2=-\u001b[32m1\u001b[39m).log().sum(-\u001b[32m1\u001b[39m)\n\u001b[32m    254\u001b[39m )\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "# ── Training + Evaluation Loop ──────────────────────────────────────────\n",
    "for epoch in range(1, cfg['epochs']+1):\n",
    "    # train\n",
    "    b1.train(); b2.train(); b3.train(); b5.train(); fusion.train()\n",
    "    total_loss = 0.0\n",
    "    for feats, labels, sections in train_loader:\n",
    "        feats = feats.squeeze()        # now [B, H, W]\n",
    "        feats = feats.unsqueeze(1)     # back to [B, 1, H, W]\n",
    "        print(feats.shape)\n",
    "        feats  = feats.to(device)  # shape: [B,1,H,W]\n",
    "        labels = labels.to(device)\n",
    "        # forward each branch\n",
    "        z1 = b1(feats)  \n",
    "        print(f\"z1.shape = {z1.shape}\")\n",
    "        recon2, z2 = b2(feats)\n",
    "        print(f\"recon2.shape = {recon2.shape}, feats.shape = {feats.shape}\")\n",
    "        print(f\"z2.shape = {z2.shape}\")\n",
    "        feats_ds = adaptive_avg_pool2d(feats, (cfg['n_mels'], recon2.shape[-1]))\n",
    "        loss2 = F.mse_loss(recon2, feats_ds)\n",
    "        z3, loss3 = b3(feats, labels)\n",
    "        print(f\"z3.shape = {z3.shape}, feats_ds.shape = {feats_ds.shape}\")\n",
    "        # loss4    = b4(feats)\n",
    "        z_cat    = torch.cat([z1, z2, z3], dim=1)\n",
    "        loss5    = b5(z_cat)\n",
    "\n",
    "        total_branch_loss = (\n",
    "            cfg['w2']*loss2 + \n",
    "            cfg['w3']*loss3 +\n",
    "            # cfg['w4']*loss4 + \n",
    "            cfg['w5']*loss5\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        total_branch_loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += total_branch_loss.item()\n",
    "\n",
    "    # evaluate\n",
    "    epoch_results = evaluate(fusion, eval_loader, device)\n",
    "    epoch_auc     = sum(r['AUC'] for r in epoch_results) / len(epoch_results)\n",
    "\n",
    "    # save checkpoints\n",
    "    save_checkpoint(fusion, optimizer, epoch,\n",
    "                    os.path.join(cfg['save_dir'], 'checkpoint_last.pth'))\n",
    "    if epoch_auc > best_auc:\n",
    "        best_auc = epoch_auc\n",
    "        save_checkpoint(fusion, optimizer, epoch,\n",
    "                        os.path.join(cfg['save_dir'], 'checkpoint_best.pth'))\n",
    "\n",
    "    # dump metrics\n",
    "    df = pd.DataFrame(epoch_results)[ result_column_dict['single_domain'] ]\n",
    "    df['epoch'] = epoch\n",
    "    if epoch == 1:\n",
    "        df.to_csv(metrics_csv, index=False)\n",
    "    else:\n",
    "        df.to_csv(metrics_csv, mode='a', header=False, index=False)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{cfg['epochs']} — TrainLoss: {total_loss/len(train_loader):.4f} — Dev AUC: {epoch_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7035f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats.squeeze(dim=3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcf3792",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "octa312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
