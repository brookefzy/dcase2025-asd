{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10d5913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, ConcatDataset, Dataset\n",
    "import os\n",
    "from datasets.dataset_spec import SpectrogramDataset\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, precision_score,\n",
    "    recall_score, f1_score\n",
    ")\n",
    "\n",
    "from datasets.loader_common import (\n",
    "    select_dirs,\n",
    "    get_machine_type_dict,\n",
    ")\n",
    "from models.branch_pretrained    import BranchPretrained\n",
    "from models.branch_transformer_ae import BranchTransformerAE\n",
    "from models.branch_contrastive   import BranchContrastive\n",
    "from models.branch_diffusion     import BranchDiffusion\n",
    "from models.branch_flow          import BranchFlow\n",
    "from models.fusion_attention     import FusionAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0584b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result columns you requested\n",
    "result_column_dict = {\n",
    "    \"single_domain\": [\n",
    "        \"section\", \"AUC\", \"pAUC\", \"precision\", \"recall\", \"F1 score\"\n",
    "    ],\n",
    "    \"source_target\": [\n",
    "        \"section\",\n",
    "        \"AUC (source)\", \"AUC (target)\",\n",
    "        \"pAUC\",\n",
    "        \"pAUC (source)\", \"pAUC (target)\",\n",
    "        \"precision (source)\", \"precision (target)\",\n",
    "        \"recall (source)\", \"recall (target)\",\n",
    "        \"F1 score (source)\", \"F1 score (target)\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9dfe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, path):\n",
    "    torch.save({\n",
    "        'epoch':       epoch,\n",
    "        'model_state': model.state_dict(),\n",
    "        'optim_state': optimizer.state_dict()\n",
    "    }, path)\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    secs, scores, labels = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for feats, labs, section in loader:\n",
    "            feats = feats.to(device)\n",
    "            # forward through branches + fusion:\n",
    "            z1 = b1(feats.unsqueeze(1))                # add channel dim: [B,1,n_mels,T]\n",
    "            recon2, z2 = b2(feats.unsqueeze(1))\n",
    "            z3, loss3  = b3(feats.unsqueeze(1), None, None)  # returns z only\n",
    "            loss4 = b4(feats.unsqueeze(1))\n",
    "            z_cat = torch.cat([z1, z2, z3], dim=1)\n",
    "            loss5 = b5(z_cat)\n",
    "            scores_batch = fusion(torch.stack([loss3, loss4, loss5, loss5, loss5], dim=1))\n",
    "            scores.extend(scores_batch.cpu().tolist())\n",
    "            labels.extend(labs.tolist())\n",
    "            secs.extend(section)\n",
    "\n",
    "    # aggregate per-section\n",
    "    df = pd.DataFrame({'section': secs, 'score': scores, 'label': labels})\n",
    "    results = []\n",
    "    for sec, grp in df.groupby('section'):\n",
    "        y_true  = grp['label'].values\n",
    "        y_score = grp['score'].values\n",
    "        auc_val   = roc_auc_score(y_true, y_score)\n",
    "        p_auc_val = roc_auc_score(y_true, y_score, max_fpr=0.1)\n",
    "        preds     = (y_score >= 0.5).astype(int)\n",
    "        prec      = precision_score(y_true, preds, zero_division=0)\n",
    "        rec       = recall_score(y_true, preds, zero_division=0)\n",
    "        f1        = f1_score(y_true, preds, zero_division=0)\n",
    "        results.append({\n",
    "            'section':  sec,\n",
    "            'AUC':      auc_val,\n",
    "            'pAUC':     p_auc_val,\n",
    "            'precision':prec,\n",
    "            'recall':   rec,\n",
    "            'F1 score': f1\n",
    "        })\n",
    "    return results\n",
    "\n",
    "\n",
    "# wrap to attach labels & section\n",
    "class WrappedSpecDS(Dataset):\n",
    "    def __init__(self, ds, train: bool):\n",
    "        self.ds    = ds\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # grab whatever the underlying dataset returns\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        # unpack first two elements, ignore any extras\n",
    "        spec, fname, *rest = item   # rest could be an attr‐dict, metadata, etc.\n",
    "\n",
    "        # label = 0 for normal in train, or infer anomaly from filename\n",
    "        lbl = 0 if self.train else int(\"_anomaly_\" in fname)\n",
    "\n",
    "        # extract section code (e.g. \"00\")\n",
    "        sec = fname.split(\"_\")[1]\n",
    "\n",
    "        return spec, lbl, sec\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pad_collate(batch):\n",
    "    specs, labels, secs = zip(*batch)  \n",
    "    # each spec is [1, H, Wi]\n",
    "    max_W = max(s.shape[-1] for s in specs)\n",
    "    padded = [\n",
    "        F.pad(s, (0, max_W - s.shape[-1]))   # keeps shape [1, H, max_W]\n",
    "        for s in specs\n",
    "    ]\n",
    "    specs_tensor = torch.stack(padded, dim=0)  # [B,1,H,max_W]\n",
    "    labels_tensor = torch.tensor(labels)\n",
    "    return specs_tensor, labels_tensor, list(secs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad990c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Settings ───────────────────────────────────────────────────────────\n",
    "mode            = 'dev'\n",
    "config_path     = \"/lustre1/g/geog_pyloo/11_octa/dcase2025_task2/config.yaml\"\n",
    "baseline_config = \"/lustre1/g/geog_pyloo/11_octa/dcase2023_task2_baseline_ae/baseline.yaml\"\n",
    "device          = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cfg     = yaml.safe_load(open(config_path))\n",
    "root    = cfg['dev_data_root'] if mode=='dev' else cfg['eval_data_root']\n",
    "name    = 'DCASE2025T2'\n",
    "param   = yaml.safe_load(open(baseline_config))\n",
    "param[\"dev_directory\"] = \"/lustre1/g/geog_pyloo/11_octa/dcase2023_task2_baseline_ae/data/dcase2025t2/dev_data/raw\"\n",
    "base_dirs = select_dirs(param, mode=(mode=='dev'))\n",
    "\n",
    "mt_dict   = get_machine_type_dict(name, mode=(mode=='dev'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd71d7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dsets = []\n",
    "eval_dsets  = []\n",
    "\n",
    "for mt, sect_info in mt_dict['machine_type'].items():\n",
    "    for sec in sect_info['dev']:\n",
    "        # raw spectrogram datasets:\n",
    "        ds_train_raw = SpectrogramDataset(\n",
    "            base_dir     = cfg['dev_data_root'],\n",
    "            machine_type = mt,\n",
    "            section      = sec,\n",
    "            mode         = 'train',\n",
    "            config       = cfg\n",
    "        )\n",
    "        ds_sup_raw   = SpectrogramDataset(\n",
    "            base_dir     = cfg['dev_data_root'],\n",
    "            machine_type = mt,\n",
    "            section      = sec,\n",
    "            mode         = 'supplemental',\n",
    "            config       = cfg\n",
    "        )\n",
    "        ds_test_raw  = SpectrogramDataset(\n",
    "            base_dir     = cfg['dev_data_root'],\n",
    "            machine_type = mt,\n",
    "            section      = sec,\n",
    "            mode         = 'test',\n",
    "            config       = cfg\n",
    "        )\n",
    "\n",
    "        # wrap them so that each sample = (spec, label:int, section:str)\n",
    "        if len(ds_train_raw):\n",
    "            train_dsets.append(WrappedSpecDS(ds_train_raw, train=True))\n",
    "        if len(ds_sup_raw):\n",
    "            train_dsets.append(WrappedSpecDS(ds_sup_raw,   train=True))\n",
    "        if len(ds_test_raw):\n",
    "            eval_dsets.append(WrappedSpecDS(ds_test_raw,  train=False))\n",
    "\n",
    "\n",
    "# concatenate all per-section datasets\n",
    "full_train_ds = ConcatDataset(train_dsets)\n",
    "full_eval_ds  = ConcatDataset(eval_dsets)\n",
    "\n",
    "# finally, wrap in DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    full_train_ds,\n",
    "    batch_size=cfg['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=pad_collate\n",
    ")\n",
    "\n",
    "eval_loader = DataLoader(\n",
    "    full_eval_ds,\n",
    "    batch_size   = cfg['batch_size'],\n",
    "    shuffle      = False,\n",
    "    # num_workers  = cfg.get('num_workers', 4)\n",
    "    num_workers = 0,\n",
    "    collate_fn=pad_collate\n",
    ")\n",
    "\n",
    "\n",
    "# ── Instantiate branches ────────────────────────────────────────────────\n",
    "b1 = BranchPretrained(cfg['ast_model'], cfg).to(device)\n",
    "b2 = BranchTransformerAE(cfg['latent_dim'], cfg).to(device)\n",
    "\n",
    "print(\"AE pos-emb len:\", b2.encoder.embeddings.position_embeddings.shape[1])\n",
    "print(\"Expected seq_len:\", 2 + ((cfg['n_mels'] - b2.encoder.config.patch_size)//b2.encoder.config.frequency_stride + 1) *\n",
    "                                ((cfg['time_steps'] - b2.encoder.config.patch_size)//b2.encoder.config.time_stride + 1))\n",
    "\n",
    "b3 = BranchContrastive(cfg['latent_dim']).to(device)\n",
    "b4 = BranchDiffusion(\n",
    "    image_size     = cfg['n_mels'],                # height of spectrogram\n",
    "    unet_dim       = cfg['diffusion_unet_dim'],    # UNet base channels\n",
    "    unet_dim_mults = tuple(cfg['diffusion_mults']),# UNet channel multipliers\n",
    "    timesteps      = cfg['diffusion_steps']        # diffusion steps\n",
    ").to(device)\n",
    "b5     = BranchFlow(cfg['flow_dim']).to(device)\n",
    "fusion = FusionAttention(num_branches=5).to(device)\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    list(b1.parameters()) + list(b2.parameters()) +\n",
    "    list(b3.parameters()) + list(b4.parameters()) +\n",
    "    list(b5.parameters()) + list(fusion.parameters()),\n",
    "    lr=float(cfg['lr'])\n",
    ")\n",
    "\n",
    "best_auc = 0.0\n",
    "os.makedirs(cfg['save_dir'], exist_ok=True)\n",
    "\n",
    "metrics_csv = os.path.join(cfg['save_dir'], 'metrics_all_epochs.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472636d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b1.train(); b2.train(); b3.train(); b4.train(); b5.train(); fusion.train()\n",
    "# with torch.no_grad():\n",
    "#     dummy = torch.randn(2,1, cfg['n_mels'], cfg['time_steps']).to(device)\n",
    "#     z1 = b1(dummy)  # should now succeed without errors\n",
    "# print(\"BranchPretrained forward OK →\", z1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099fa7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Training + Evaluation Loop ──────────────────────────────────────────\n",
    "for epoch in range(1, cfg['epochs']+1):\n",
    "    # train\n",
    "    b1.train(); b2.train(); b3.train(); b4.train(); b5.train(); fusion.train()\n",
    "    total_loss = 0.0\n",
    "    for feats, labels, sections in train_loader:\n",
    "        feats = feats.squeeze()        # now [B, H, W]\n",
    "        feats = feats.unsqueeze(1)     # back to [B, 1, H, W]\n",
    "        print(feats.shape)\n",
    "        feats  = feats.to(device)  # shape: [B,1,H,W]\n",
    "        labels = labels.to(device)\n",
    "        # forward each branch\n",
    "        z1 = b1(feats)  \n",
    "        recon2, z2 = b2(feats)\n",
    "        loss2 = F.mse_loss(recon2, feats)\n",
    "        z3, loss3 = b3(feats, None, None)\n",
    "        loss4    = b4(feats)\n",
    "        z_cat    = torch.cat([z1, z2, z3], dim=1)\n",
    "        loss5    = b5(z_cat)\n",
    "\n",
    "        total_branch_loss = (\n",
    "            cfg['w2']*loss2 + cfg['w3']*loss3 +\n",
    "            cfg['w4']*loss4 + cfg['w5']*loss5\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        total_branch_loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += total_branch_loss.item()\n",
    "\n",
    "    # evaluate\n",
    "    epoch_results = evaluate(fusion, eval_loader, device)\n",
    "    epoch_auc     = sum(r['AUC'] for r in epoch_results) / len(epoch_results)\n",
    "\n",
    "    # save checkpoints\n",
    "    save_checkpoint(fusion, optimizer, epoch,\n",
    "                    os.path.join(cfg['save_dir'], 'checkpoint_last.pth'))\n",
    "    if epoch_auc > best_auc:\n",
    "        best_auc = epoch_auc\n",
    "        save_checkpoint(fusion, optimizer, epoch,\n",
    "                        os.path.join(cfg['save_dir'], 'checkpoint_best.pth'))\n",
    "\n",
    "    # dump metrics\n",
    "    df = pd.DataFrame(epoch_results)[ result_column_dict['single_domain'] ]\n",
    "    df['epoch'] = epoch\n",
    "    if epoch == 1:\n",
    "        df.to_csv(metrics_csv, index=False)\n",
    "    else:\n",
    "        df.to_csv(metrics_csv, mode='a', header=False, index=False)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{cfg['epochs']} — TrainLoss: {total_loss/len(train_loader):.4f} — Dev AUC: {epoch_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7035f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats.squeeze(dim=3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcf3792",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "octa312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
